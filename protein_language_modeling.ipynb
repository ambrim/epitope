{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "af5d6f2e",
      "metadata": {
        "id": "af5d6f2e"
      },
      "source": [
        "If you're opening this Notebook on colab, you will probably need to install ðŸ¤— Transformers as well as some other libraries. Uncomment the following cell and run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4c5bf8d4",
      "metadata": {
        "id": "4c5bf8d4"
      },
      "outputs": [],
      "source": [
        "#!pip install transformers evaluate datasets requests pandas sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76e71a3f",
      "metadata": {
        "id": "76e71a3f"
      },
      "source": [
        "If you're opening this notebook locally, make sure your environment has an install from the last version of those libraries.\n",
        "\n",
        "To be able to share your model with the community and generate results like the one shown in the picture below via the inference API, there are a few more steps to follow.\n",
        "\n",
        "First you have to store your authentication token from the Hugging Face website (sign up here if you haven't already!) then execute the following cell and input your username and password:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "25b8526a",
      "metadata": {
        "id": "25b8526a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3618eda2a214738b8c3212402dd5a04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab8b2712",
      "metadata": {
        "id": "ab8b2712"
      },
      "source": [
        "Then you need to install Git-LFS. Uncomment the following instructions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "19e8f77c",
      "metadata": {
        "id": "19e8f77c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The operation couldnâ€™t be completed. Unable to locate a Java Runtime that supports apt.\n",
            "Please visit http://www.java.com for information on installing Java.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!apt install git-lfs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80dbad4e",
      "metadata": {
        "id": "80dbad4e"
      },
      "source": [
        "We also quickly upload some telemetry - this tells us which examples and software versions are getting used so we know where to prioritize our maintenance efforts. We don't collect (or care about) any personally identifiable information, but if you'd prefer not to be counted, feel free to skip this step or delete this cell entirely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d107b8d9",
      "metadata": {
        "id": "d107b8d9"
      },
      "outputs": [],
      "source": [
        "from transformers.utils import send_example_telemetry\n",
        "\n",
        "send_example_telemetry(\"protein_language_modeling_notebook\", framework=\"pytorch\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c0749e1",
      "metadata": {
        "id": "5c0749e1"
      },
      "source": [
        "# Fine-Tuning Protein Language Models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d81db83",
      "metadata": {
        "id": "1d81db83"
      },
      "source": [
        "In this notebook, we're going to do some transfer learning to fine-tune some large, pre-trained protein language models on tasks of interest. If that sentence feels a bit intimidating to you, don't panic - there's [a blog post](https://huggingface.co/blog/deep-learning-with-proteins) that explains the concepts here in much more detail.\n",
        "\n",
        "The specific model we're going to use is ESM-2, which is the state-of-the-art protein language model at the time of writing (November 2022). The citation for this model is [Lin et al, 2022](https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1).\n",
        "\n",
        "There are several ESM-2 checkpoints with differing model sizes. Larger models will generally have better accuracy, but they require more GPU memory and will take much longer to train. The available ESM-2 checkpoints (at time of writing) are:\n",
        "\n",
        "| Checkpoint name | Num layers | Num parameters |\n",
        "|------------------------------|----|----------|\n",
        "| `esm2_t48_15B_UR50D`         | 48 | 15B     |\n",
        "| `esm2_t36_3B_UR50D`          | 36 | 3B      |\n",
        "| `esm2_t33_650M_UR50D`        | 33 | 650M    |\n",
        "| `esm2_t30_150M_UR50D`        | 30 | 150M    |\n",
        "| `esm2_t12_35M_UR50D`         | 12 | 35M     |\n",
        "| `esm2_t6_8M_UR50D`           | 6  | 8M      |\n",
        "\n",
        "Note that the larger checkpoints may be very difficult to train without a large cloud GPU like an A100 or H100, and the largest 15B parameter checkpoint will probably be impossible to train on **any** single GPU! Also, note that memory usage for attention during training will scale as `O(batch_size * num_layers * seq_len^2)`, so larger models on long sequences will use quite a lot of memory! We will use the `esm2_t12_35M_UR50D` checkpoint for this notebook, which should train on any Colab instance or modern GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "32e605a2",
      "metadata": {
        "id": "32e605a2"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = \"facebook/esm2_t12_35M_UR50D\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8e6ac19",
      "metadata": {
        "id": "a8e6ac19"
      },
      "source": [
        "# Sequence classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3eb400c",
      "metadata": {
        "id": "c3eb400c"
      },
      "source": [
        "One of the most common tasks you can perform with a language model is **sequence classification**. In sequence classification, we classify an entire protein into a category, from a list of two or more possibilities. There's no limit on the number of categories you can use, or the specific problem you choose, as long as it's something the model could in theory infer from the raw protein sequence. To keep things simple for this example, though, let's try classifying proteins by their cellular localization - given their sequence, can we predict if they're going to be found in the cytosol (the fluid inside the cell) or embedded in the cell membrane?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5bc122f",
      "metadata": {
        "id": "c5bc122f"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c91d394",
      "metadata": {
        "id": "4c91d394"
      },
      "source": [
        "In this section, we're going to gather some training data from UniProt. Our goal is to create a pair of lists: `sequences` and `labels`. `sequences` will be a list of protein sequences, which will just be strings like \"MNKL...\", where each letter represents a single amino acid in the complete protein. `labels` will be a list of the category for each sequence. The categories will just be integers, with 0 representing the first category, 1 representing the second and so on. In other words, if `sequences[i]` is a protein sequence then `labels[i]` should be its corresponding category. These will form the **training data** we're going to use to teach the model the task we want it to do.\n",
        "\n",
        "If you're adapting this notebook for your own use, this will probably be the main section you want to change! You can do whatever you want here, as long as you create those two lists by the end of it. If you want to follow along with this example, though, first we'll need to `import requests` and set up our query to UniProt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c718ffbc",
      "metadata": {
        "id": "c718ffbc"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "query_url =\"https://rest.uniprot.org/uniprotkb/stream?compressed=true&fields=accession%2Csequence%2Ccc_subcellular_location&format=tsv&query=%28%28organism_id%3A9606%29%20AND%20%28reviewed%3Atrue%29%20AND%20%28length%3A%5B80%20TO%20500%5D%29%29\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d2edc14",
      "metadata": {
        "id": "3d2edc14"
      },
      "source": [
        "This query URL might seem mysterious, but it isn't! To get it, we searched for `(organism_id:9606) AND (reviewed:true) AND (length:[80 TO 500])` on UniProt to get a list of reasonably-sized human proteins,\n",
        "then selected 'Download', and set the format to TSV and the columns to `Sequence` and `Subcellular location [CC]`, since those contain the data we care about for this task.\n",
        "\n",
        "Once that's done, selecting `Generate URL for API` gives you a URL you can pass to Requests. Alternatively, if you're not on Colab you can just download the data through the web interface and open the file locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dd03ef98",
      "metadata": {
        "id": "dd03ef98"
      },
      "outputs": [],
      "source": [
        "uniprot_request = requests.get(query_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7217b77",
      "metadata": {
        "id": "b7217b77"
      },
      "source": [
        "To get this data into Pandas, we use a `BytesIO` object, which Pandas will treat like a file. If you downloaded the data as a file you can skip this bit and just pass the filepath directly to `read_csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f2c05017",
      "metadata": {
        "id": "f2c05017",
        "outputId": "050ea432-9a34-4cbe-a064-298b1df0e4a2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Entry</th>\n",
              "      <th>Sequence</th>\n",
              "      <th>Subcellular location [CC]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A0A0K2S4Q6</td>\n",
              "      <td>MTQRAGAAMLPSALLLLCVPGCLTVSGPSTVMGAVGESLSVQCRYE...</td>\n",
              "      <td>SUBCELLULAR LOCATION: [Isoform 1]: Membrane {E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A0AVI4</td>\n",
              "      <td>MDSPEVTFTLAYLVFAVCFVFTPNEFHAAGLTVQNLLSGWLGSEDA...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Endoplasmic reticulum me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A0JLT2</td>\n",
              "      <td>MENFTALFGAQADPPPPPTALGFGPGKPPPPPPPPAGGGPGTAPPP...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Nucleus {ECO:0000305}.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A0M8Q6</td>\n",
              "      <td>GQPKAAPSVTLFPPSSEELQANKATLVCLVSDFNPGAVTVAWKADG...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Secreted {ECO:0000303|Pu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A0PJY2</td>\n",
              "      <td>MDSSCHNATTKMLATAPARGNMMSTSKPLAFSIERIMARTPEPKAL...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Nucleus {ECO:0000269|Pub...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11985</th>\n",
              "      <td>Q9HBI5</td>\n",
              "      <td>MTSLFAQEIRLSKRHEEIVSQRLMLLQQMENKLGDQHTEKASQLQT...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Cell projection, cilium ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11986</th>\n",
              "      <td>Q9NZ38</td>\n",
              "      <td>MAFPGQSDTKMQWPEVPALPLLSSLCMAMVRKSSALGKEVGRRSEG...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11987</th>\n",
              "      <td>Q9UFV3</td>\n",
              "      <td>MAETYRRSRQHEQLPGQRHMDLLTGYSKLIQSRLKLLLHLGSQPPV...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11988</th>\n",
              "      <td>Q9Y6C7</td>\n",
              "      <td>MAHHSLNTFYIWHNNVLHTHLVFFLPHLLNQPFSRGSFLIWLLLCW...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11989</th>\n",
              "      <td>X6R8R1</td>\n",
              "      <td>MGVVLSPHPAPSRREPLAPLAPGTRPGWSPAVSGSSRSALRPSTAG...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11990 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Entry                                           Sequence  \\\n",
              "0      A0A0K2S4Q6  MTQRAGAAMLPSALLLLCVPGCLTVSGPSTVMGAVGESLSVQCRYE...   \n",
              "1          A0AVI4  MDSPEVTFTLAYLVFAVCFVFTPNEFHAAGLTVQNLLSGWLGSEDA...   \n",
              "2          A0JLT2  MENFTALFGAQADPPPPPTALGFGPGKPPPPPPPPAGGGPGTAPPP...   \n",
              "3          A0M8Q6  GQPKAAPSVTLFPPSSEELQANKATLVCLVSDFNPGAVTVAWKADG...   \n",
              "4          A0PJY2  MDSSCHNATTKMLATAPARGNMMSTSKPLAFSIERIMARTPEPKAL...   \n",
              "...           ...                                                ...   \n",
              "11985      Q9HBI5  MTSLFAQEIRLSKRHEEIVSQRLMLLQQMENKLGDQHTEKASQLQT...   \n",
              "11986      Q9NZ38  MAFPGQSDTKMQWPEVPALPLLSSLCMAMVRKSSALGKEVGRRSEG...   \n",
              "11987      Q9UFV3  MAETYRRSRQHEQLPGQRHMDLLTGYSKLIQSRLKLLLHLGSQPPV...   \n",
              "11988      Q9Y6C7  MAHHSLNTFYIWHNNVLHTHLVFFLPHLLNQPFSRGSFLIWLLLCW...   \n",
              "11989      X6R8R1  MGVVLSPHPAPSRREPLAPLAPGTRPGWSPAVSGSSRSALRPSTAG...   \n",
              "\n",
              "                               Subcellular location [CC]  \n",
              "0      SUBCELLULAR LOCATION: [Isoform 1]: Membrane {E...  \n",
              "1      SUBCELLULAR LOCATION: Endoplasmic reticulum me...  \n",
              "2           SUBCELLULAR LOCATION: Nucleus {ECO:0000305}.  \n",
              "3      SUBCELLULAR LOCATION: Secreted {ECO:0000303|Pu...  \n",
              "4      SUBCELLULAR LOCATION: Nucleus {ECO:0000269|Pub...  \n",
              "...                                                  ...  \n",
              "11985  SUBCELLULAR LOCATION: Cell projection, cilium ...  \n",
              "11986                                                NaN  \n",
              "11987                                                NaN  \n",
              "11988                                                NaN  \n",
              "11989                                                NaN  \n",
              "\n",
              "[11990 rows x 3 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from io import BytesIO\n",
        "import pandas\n",
        "\n",
        "bio = BytesIO(uniprot_request.content)\n",
        "\n",
        "df = pandas.read_csv(bio, compression='gzip', sep='\\t')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bcdf34b",
      "metadata": {
        "id": "0bcdf34b"
      },
      "source": [
        "Nice! Now we have some proteins and their subcellular locations. Let's start filtering this down. First, let's ditch the columns without subcellular location information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "31d87663",
      "metadata": {
        "id": "31d87663"
      },
      "outputs": [],
      "source": [
        "df = df.dropna()  # Drop proteins with missing columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10d1af5c",
      "metadata": {
        "id": "10d1af5c"
      },
      "source": [
        "Now we'll make one dataframe of proteins that contain `cytosol` or `cytoplasm` in their subcellular localization column, and a second that mentions the `membrane` or `cell membrane`. To ensure we don't get overlap, we ensure each dataframe only contains proteins that don't match the other search term."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c831bb16",
      "metadata": {
        "id": "c831bb16"
      },
      "outputs": [],
      "source": [
        "cytosolic = df['Subcellular location [CC]'].str.contains(\"Cytosol\") | df['Subcellular location [CC]'].str.contains(\"Cytoplasm\")\n",
        "membrane = df['Subcellular location [CC]'].str.contains(\"Membrane\") | df['Subcellular location [CC]'].str.contains(\"Cell membrane\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f41139a2",
      "metadata": {
        "id": "f41139a2",
        "outputId": "c4f236d8-d5b5-474b-fce5-35887f5cda91"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Entry</th>\n",
              "      <th>Sequence</th>\n",
              "      <th>Subcellular location [CC]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>A1E959</td>\n",
              "      <td>MKIIILLGFLGATLSAPLIPQRLMSASNSNELLLNLNNGQLLPLQL...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Secreted {ECO:0000250|Un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>A1XBS5</td>\n",
              "      <td>MMRRTLENRNAQTKQLQTAVSNVEKHFGELCQIFAAYVRKTARLRD...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Cytoplasm {ECO:0000269|P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>A2RU49</td>\n",
              "      <td>MSSGNYQQSEALSKPTFSEEQASALVESVFGLKVSKVRPLPSYDDQ...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Cytoplasm {ECO:0000305}.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>A2RUH7</td>\n",
              "      <td>MEAATAPEVAAGSKLKVKEASPADAEPPQASPGQGAGSPTPQLLPP...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Cytoplasm, myofibril, sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>A4D126</td>\n",
              "      <td>MEAGPPGSARPAEPGPCLSGQRGADHTASASLQSVAGTEPGRHPQA...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Cytoplasm, cytosol {ECO:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11607</th>\n",
              "      <td>Q9BYD9</td>\n",
              "      <td>MNHCQLPVVIDNGSGMIKAGVAGCREPQFIYPNIIGRAKGQSRAAQ...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Cytoplasm, cytoskeleton ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11647</th>\n",
              "      <td>Q9NPB0</td>\n",
              "      <td>MEQRLAEFRAARKRAGLAAQPPAASQGAQTPGEKAEAAATLKAAPG...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Cytoplasmic vesicle memb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11659</th>\n",
              "      <td>Q9NUJ7</td>\n",
              "      <td>MGGQVSASNSFSRLHCRNANEDWMSALCPRLWDVPLHHLSIPGSHD...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Cytoplasm {ECO:0000269|P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11661</th>\n",
              "      <td>Q9NVM6</td>\n",
              "      <td>MAVTKELLQMDLYALLGIEEKAADKEVKKAYRQKALSCHPDKNPDN...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Cytoplasm {ECO:0000250|U...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11671</th>\n",
              "      <td>Q9P2W6</td>\n",
              "      <td>MGRTWCGMWRRRRPGRRSAVPRWPHLSSQSGVEPPDRWTGTPGWPS...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Cytoplasm.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2571 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Entry                                           Sequence  \\\n",
              "9      A1E959  MKIIILLGFLGATLSAPLIPQRLMSASNSNELLLNLNNGQLLPLQL...   \n",
              "14     A1XBS5  MMRRTLENRNAQTKQLQTAVSNVEKHFGELCQIFAAYVRKTARLRD...   \n",
              "18     A2RU49  MSSGNYQQSEALSKPTFSEEQASALVESVFGLKVSKVRPLPSYDDQ...   \n",
              "20     A2RUH7  MEAATAPEVAAGSKLKVKEASPADAEPPQASPGQGAGSPTPQLLPP...   \n",
              "21     A4D126  MEAGPPGSARPAEPGPCLSGQRGADHTASASLQSVAGTEPGRHPQA...   \n",
              "...       ...                                                ...   \n",
              "11607  Q9BYD9  MNHCQLPVVIDNGSGMIKAGVAGCREPQFIYPNIIGRAKGQSRAAQ...   \n",
              "11647  Q9NPB0  MEQRLAEFRAARKRAGLAAQPPAASQGAQTPGEKAEAAATLKAAPG...   \n",
              "11659  Q9NUJ7  MGGQVSASNSFSRLHCRNANEDWMSALCPRLWDVPLHHLSIPGSHD...   \n",
              "11661  Q9NVM6  MAVTKELLQMDLYALLGIEEKAADKEVKKAYRQKALSCHPDKNPDN...   \n",
              "11671  Q9P2W6  MGRTWCGMWRRRRPGRRSAVPRWPHLSSQSGVEPPDRWTGTPGWPS...   \n",
              "\n",
              "                               Subcellular location [CC]  \n",
              "9      SUBCELLULAR LOCATION: Secreted {ECO:0000250|Un...  \n",
              "14     SUBCELLULAR LOCATION: Cytoplasm {ECO:0000269|P...  \n",
              "18        SUBCELLULAR LOCATION: Cytoplasm {ECO:0000305}.  \n",
              "20     SUBCELLULAR LOCATION: Cytoplasm, myofibril, sa...  \n",
              "21     SUBCELLULAR LOCATION: Cytoplasm, cytosol {ECO:...  \n",
              "...                                                  ...  \n",
              "11607  SUBCELLULAR LOCATION: Cytoplasm, cytoskeleton ...  \n",
              "11647  SUBCELLULAR LOCATION: Cytoplasmic vesicle memb...  \n",
              "11659  SUBCELLULAR LOCATION: Cytoplasm {ECO:0000269|P...  \n",
              "11661  SUBCELLULAR LOCATION: Cytoplasm {ECO:0000250|U...  \n",
              "11671                   SUBCELLULAR LOCATION: Cytoplasm.  \n",
              "\n",
              "[2571 rows x 3 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cytosolic_df = df[cytosolic & ~membrane]\n",
        "cytosolic_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "be5c420e",
      "metadata": {
        "id": "be5c420e",
        "outputId": "23d3fe60-6d2c-4049-9262-58a6df8a9e81"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Entry</th>\n",
              "      <th>Sequence</th>\n",
              "      <th>Subcellular location [CC]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A0A0K2S4Q6</td>\n",
              "      <td>MTQRAGAAMLPSALLLLCVPGCLTVSGPSTVMGAVGESLSVQCRYE...</td>\n",
              "      <td>SUBCELLULAR LOCATION: [Isoform 1]: Membrane {E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A0M8Q6</td>\n",
              "      <td>GQPKAAPSVTLFPPSSEELQANKATLVCLVSDFNPGAVTVAWKADG...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Secreted {ECO:0000303|Pu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>A2RU14</td>\n",
              "      <td>MAGTVLGVGAGVFILALLWVAVLLLCVLLSRASGAARFSVIFLFFG...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>A5X5Y0</td>\n",
              "      <td>MEGSWFHRKRFSFYLLLGFLLQGRGVTFTINCSGFGQHGADPTALN...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Postsynaptic cell membra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>A6ND01</td>\n",
              "      <td>MACWWPLLLELWTVMPTWAGDELLNICMNAKHHKRVPSPEDKLYEE...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Cell membrane {ECO:00002...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11901</th>\n",
              "      <td>Q86UQ5</td>\n",
              "      <td>MQSDIYHPGHSFPSWVLCWVHSCGHEGHLRETAEIRKTHQNGDLQI...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11927</th>\n",
              "      <td>Q8N8V8</td>\n",
              "      <td>MLLKVRRASLKPPATPHQGAFRAGNVIGQLIYLLTWSLFTAWLRPP...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11967</th>\n",
              "      <td>Q96N68</td>\n",
              "      <td>MQGQGALKESHIHLPTEQPEASLVLQGQLAESSALGPKGALRPQAQ...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11974</th>\n",
              "      <td>Q9H0A3</td>\n",
              "      <td>MMNNTDFLMLNNPWNKLCLVSMDFCFPLDFVSNLFWIFASKFIIVT...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Membrane {ECO:0000255}; ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11977</th>\n",
              "      <td>Q9H354</td>\n",
              "      <td>MNKHNLRLVQLASELILIEIIPKLFLSQVTTISHIKREKIPPNHRK...</td>\n",
              "      <td>SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2552 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Entry                                           Sequence  \\\n",
              "0      A0A0K2S4Q6  MTQRAGAAMLPSALLLLCVPGCLTVSGPSTVMGAVGESLSVQCRYE...   \n",
              "3          A0M8Q6  GQPKAAPSVTLFPPSSEELQANKATLVCLVSDFNPGAVTVAWKADG...   \n",
              "17         A2RU14  MAGTVLGVGAGVFILALLWVAVLLLCVLLSRASGAARFSVIFLFFG...   \n",
              "33         A5X5Y0  MEGSWFHRKRFSFYLLLGFLLQGRGVTFTINCSGFGQHGADPTALN...   \n",
              "36         A6ND01  MACWWPLLLELWTVMPTWAGDELLNICMNAKHHKRVPSPEDKLYEE...   \n",
              "...           ...                                                ...   \n",
              "11901      Q86UQ5  MQSDIYHPGHSFPSWVLCWVHSCGHEGHLRETAEIRKTHQNGDLQI...   \n",
              "11927      Q8N8V8  MLLKVRRASLKPPATPHQGAFRAGNVIGQLIYLLTWSLFTAWLRPP...   \n",
              "11967      Q96N68  MQGQGALKESHIHLPTEQPEASLVLQGQLAESSALGPKGALRPQAQ...   \n",
              "11974      Q9H0A3  MMNNTDFLMLNNPWNKLCLVSMDFCFPLDFVSNLFWIFASKFIIVT...   \n",
              "11977      Q9H354  MNKHNLRLVQLASELILIEIIPKLFLSQVTTISHIKREKIPPNHRK...   \n",
              "\n",
              "                               Subcellular location [CC]  \n",
              "0      SUBCELLULAR LOCATION: [Isoform 1]: Membrane {E...  \n",
              "3      SUBCELLULAR LOCATION: Secreted {ECO:0000303|Pu...  \n",
              "17     SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...  \n",
              "33     SUBCELLULAR LOCATION: Postsynaptic cell membra...  \n",
              "36     SUBCELLULAR LOCATION: Cell membrane {ECO:00002...  \n",
              "...                                                  ...  \n",
              "11901  SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...  \n",
              "11927  SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...  \n",
              "11967  SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...  \n",
              "11974  SUBCELLULAR LOCATION: Membrane {ECO:0000255}; ...  \n",
              "11977  SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...  \n",
              "\n",
              "[2552 rows x 3 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "membrane_df = df[membrane & ~cytosolic]\n",
        "membrane_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77e8cea6",
      "metadata": {
        "id": "77e8cea6"
      },
      "source": [
        "We're almost done! Now, let's make a list of sequences from each df and generate the associated labels. We'll use `0` as the label for cytosolic proteins and `1` as the label for membrane proteins."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "023ec31b",
      "metadata": {
        "id": "023ec31b"
      },
      "outputs": [],
      "source": [
        "cytosolic_sequences = cytosolic_df[\"Sequence\"].tolist()\n",
        "cytosolic_labels = [0 for protein in cytosolic_sequences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d0e7318b",
      "metadata": {
        "id": "d0e7318b"
      },
      "outputs": [],
      "source": [
        "membrane_sequences = membrane_df[\"Sequence\"].tolist()\n",
        "membrane_labels = [1 for protein in membrane_sequences]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a4bbda2",
      "metadata": {
        "id": "5a4bbda2"
      },
      "source": [
        "Now we can concatenate these lists together to get the `sequences` and `labels` lists that will form our final training data. Don't worry - they'll get shuffled during training!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7dec7a4a",
      "metadata": {
        "id": "7dec7a4a",
        "outputId": "d9497013-050c-4060-83aa-d6396072522c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequences = cytosolic_sequences + membrane_sequences\n",
        "labels = cytosolic_labels + membrane_labels\n",
        "\n",
        "# Quick check to make sure we got it right\n",
        "len(sequences) == len(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc782dd0",
      "metadata": {
        "id": "bc782dd0"
      },
      "source": [
        "Phew!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0aac39c",
      "metadata": {
        "id": "e0aac39c"
      },
      "source": [
        "## Splitting the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9099e7c",
      "metadata": {
        "id": "a9099e7c"
      },
      "source": [
        "Since the data we're loading isn't prepared for us as a machine learning dataset, we'll have to split the data into train and test sets ourselves! We can use sklearn's function for that:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "366147ad",
      "metadata": {
        "id": "366147ad"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sequences, test_sequences, train_labels, test_labels = train_test_split(sequences, labels, test_size=0.25, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d29b4ed",
      "metadata": {
        "id": "7d29b4ed"
      },
      "source": [
        "## Tokenizing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c02baaf7",
      "metadata": {
        "id": "c02baaf7"
      },
      "source": [
        "All inputs to neural nets must be numerical. The process of converting strings into numerical indices suitable for a neural net is called **tokenization**. For natural language this can be quite complex, as usually the network's vocabulary will not contain every possible word, which means the tokenizer must handle splitting rarer words into pieces, as well as all the complexities of capitalization and unicode characters and so on.\n",
        "\n",
        "With proteins, however, things are very easy. In protein language models, each amino acid is converted to a single token. Every model on `transformers` comes with an associated `tokenizer` that handles tokenization for it, and protein language models are no different. Let's get our tokenizer!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ddbe2b2d",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "cc61f599adc641da8d40eefac0179aa3",
            "4e3d35bc47c74852a5256f5b34312030",
            "8b7f3b4a47d8437f9e9cc6648cfc8984"
          ]
        },
        "id": "ddbe2b2d",
        "outputId": "ef62f33e-9272-4e5d-d506-9c16f553aa28"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d16be37",
      "metadata": {
        "id": "9d16be37"
      },
      "source": [
        "Let's try a single sequence to see what the outputs from our tokenizer look like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "687386af",
      "metadata": {
        "id": "687386af",
        "outputId": "8f9170aa-ddf3-4a96-ba5e-d63910a50bf1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [0, 20, 4, 5, 17, 8, 8, 8, 11, 17, 8, 8, 7, 4, 14, 23, 14, 13, 19, 10, 14, 11, 21, 10, 4, 21, 4, 7, 7, 19, 8, 4, 7, 4, 5, 5, 6, 4, 14, 4, 17, 5, 4, 5, 4, 22, 7, 18, 4, 10, 5, 4, 10, 7, 21, 8, 7, 7, 8, 7, 19, 20, 23, 17, 4, 5, 5, 8, 13, 4, 4, 18, 11, 4, 8, 4, 14, 7, 10, 4, 8, 19, 19, 5, 4, 21, 21, 22, 14, 18, 14, 13, 4, 4, 23, 16, 11, 11, 6, 5, 12, 18, 16, 20, 17, 20, 19, 6, 8, 23, 12, 18, 4, 20, 4, 12, 17, 7, 13, 10, 19, 5, 5, 12, 7, 21, 14, 4, 10, 4, 10, 21, 4, 10, 10, 14, 10, 7, 5, 10, 4, 4, 23, 4, 6, 7, 22, 5, 4, 12, 4, 7, 18, 5, 7, 14, 5, 5, 10, 7, 21, 10, 14, 8, 10, 23, 10, 19, 10, 13, 4, 9, 7, 10, 4, 23, 18, 9, 8, 18, 8, 13, 9, 4, 22, 15, 6, 10, 4, 4, 14, 4, 7, 4, 4, 5, 9, 5, 4, 6, 18, 4, 4, 14, 4, 5, 5, 7, 7, 19, 8, 8, 6, 10, 7, 18, 22, 11, 4, 5, 10, 14, 13, 5, 11, 16, 8, 16, 10, 10, 10, 15, 11, 7, 10, 4, 4, 4, 5, 17, 4, 7, 12, 18, 4, 4, 23, 18, 7, 14, 19, 17, 8, 11, 4, 5, 7, 19, 6, 4, 4, 10, 8, 15, 4, 7, 5, 5, 8, 7, 14, 5, 10, 13, 10, 7, 10, 6, 7, 4, 20, 7, 20, 7, 4, 4, 5, 6, 5, 17, 23, 7, 4, 13, 14, 4, 7, 19, 19, 18, 8, 5, 9, 6, 18, 10, 17, 11, 4, 10, 6, 4, 6, 11, 14, 21, 10, 5, 10, 11, 8, 5, 11, 17, 6, 11, 10, 5, 5, 4, 5, 16, 8, 9, 10, 8, 5, 7, 11, 11, 13, 5, 11, 10, 14, 13, 5, 5, 8, 16, 6, 4, 4, 10, 14, 8, 13, 8, 21, 8, 4, 8, 8, 18, 11, 16, 23, 14, 16, 13, 8, 5, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(train_sequences[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a719808",
      "metadata": {
        "id": "9a719808"
      },
      "source": [
        "This looks good! We can see that our sequence has been converted into `input_ids`, which is the tokenized sequence, and an `attention_mask`. The attention mask handles the case when we have sequences of variable length - in those cases, the shorter sequences are padded with blank \"padding\" tokens, and the attention mask is padded with 0s to indicate that those tokens should be ignored by the model.\n",
        "\n",
        "So now, let's tokenize our whole dataset. Note that we don't need to do anything with the labels, as they're already in the format we need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "56e26ddf",
      "metadata": {
        "id": "56e26ddf"
      },
      "outputs": [],
      "source": [
        "train_tokenized = tokenizer(train_sequences)\n",
        "test_tokenized = tokenizer(test_sequences)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df3681d1",
      "metadata": {
        "id": "df3681d1"
      },
      "source": [
        "## Dataset creation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85089e49",
      "metadata": {
        "id": "85089e49"
      },
      "source": [
        "Now we want to turn this data into a dataset that PyTorch can load samples from. We can use the HuggingFace `Dataset` class for this, although if you prefer you can also use `torch.utils.data.Dataset`, at the cost of some more boilerplate code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "fb79ba6c",
      "metadata": {
        "id": "fb79ba6c",
        "outputId": "47d90479-683e-4673-f17c-533bd0fb27f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask'],\n",
              "    num_rows: 3842\n",
              "})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "train_dataset = Dataset.from_dict(train_tokenized)\n",
        "test_dataset = Dataset.from_dict(test_tokenized)\n",
        "\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e809e47",
      "metadata": {
        "id": "9e809e47"
      },
      "source": [
        "This looks good, but we're missing our labels! Let's add those on as an extra column to the datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "090acc0d",
      "metadata": {
        "id": "090acc0d",
        "outputId": "6405d6d1-0e5b-4765-ba88-441f0e838302"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 3842\n",
              "})"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset = train_dataset.add_column(\"labels\", train_labels)\n",
        "test_dataset = test_dataset.add_column(\"labels\", test_labels)\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ced9aaa8",
      "metadata": {
        "id": "ced9aaa8"
      },
      "source": [
        "Looks good! We're ready for training."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af074a5c",
      "metadata": {
        "id": "af074a5c"
      },
      "source": [
        "## Model loading"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccab5d70",
      "metadata": {
        "id": "ccab5d70"
      },
      "source": [
        "Next, we want to load our model. Make sure to use exactly the same model as you used when loading the tokenizer, or your model might not understand the tokenization scheme you're using!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "fc164b49",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "0fac5f3b8b894d21aee5d90b61e93313",
            "4a5dd63ce59940babe11af50992fcd2a"
          ]
        },
        "id": "fc164b49",
        "outputId": "87c1f0b0-35e1-4b67-b30f-2ec16822a5b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "num_labels = max(train_labels + test_labels) + 1  # Add 1 since 0 can be a label\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'0.24.1'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import accelerate\n",
        "\n",
        "accelerate.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49dcba23",
      "metadata": {
        "id": "49dcba23"
      },
      "source": [
        "These warnings are telling us that the model is discarding some weights that it used for language modelling (the `lm_head`) and adding some weights for sequence classification (the `classifier`). This is exactly what we expect when we want to fine-tune a language model on a sequence classification task!\n",
        "\n",
        "Next, we initialize our `TrainingArguments`. These control the various training hyperparameters, and will be passed to our `Trainer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "775cb3e7",
      "metadata": {
        "id": "775cb3e7"
      },
      "outputs": [],
      "source": [
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "batch_size = 8\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"{model_name}-finetuned-localization\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    push_to_hub=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc95d099",
      "metadata": {
        "id": "bc95d099"
      },
      "source": [
        "Next, we define the metric we will use to evaluate our models and write a `compute_metrics` function. We can load this from the `evaluate` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "471cef9f",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "55d5a21f0be54ea1b33c552fed2c3bd3"
          ]
        },
        "id": "471cef9f",
        "outputId": "9337f63a-6270-4f82-c940-8268f943ad08"
      },
      "outputs": [],
      "source": [
        "from evaluate import load\n",
        "import numpy as np\n",
        "\n",
        "metric = load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "709dcf25",
      "metadata": {
        "id": "709dcf25"
      },
      "source": [
        "And at last we're ready to initialize our `Trainer`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "e212b751",
      "metadata": {
        "id": "e212b751",
        "outputId": "4ad5cce3-63c0-4bbd-efbd-3d27016b5a70"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32924d0d",
      "metadata": {
        "id": "32924d0d"
      },
      "source": [
        "You might wonder why we pass along the `tokenizer` when we already preprocessed our data. This is because we will use it one last time to make all the samples we gather the same length by applying padding, which requires knowing the model's preferences regarding padding (to the left or right? with which token?). The `tokenizer` has a pad method that will do all of this right for us, and the `Trainer` will use it. You can customize this part by defining and passing your own `data_collator` which will receive samples like the dictionaries seen above and will need to return a dictionary of tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72f7a24c",
      "metadata": {
        "id": "72f7a24c"
      },
      "source": [
        "We can now finetune our model by just calling the `train` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "9c3cf6da",
      "metadata": {
        "id": "9c3cf6da",
        "outputId": "752949d7-784f-4026-8c6a-dd78fd942b90",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c11ec7c07dea4b508ef5b17e428d627f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1443 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/amalicema24/Downloads/esm2_pytorch/protein_language_modeling.ipynb Cell 61\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/amalicema24/Downloads/esm2_pytorch/protein_language_modeling.ipynb#Y113sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/transformers/trainer.py:1546\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     \u001b[39m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   1545\u001b[0m     hf_hub_utils\u001b[39m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 1546\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1547\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1548\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1549\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1550\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1551\u001b[0m     )\n\u001b[1;32m   1552\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1553\u001b[0m     hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/transformers/trainer.py:1837\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1834\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   1836\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1837\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1839\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1840\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1841\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1842\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1843\u001b[0m ):\n\u001b[1;32m   1844\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1845\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/transformers/trainer.py:2693\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         scaled_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m   2692\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2693\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mbackward(loss)\n\u001b[1;32m   2695\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach() \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgradient_accumulation_steps\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/accelerate/accelerator.py:1989\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1987\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1988\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1989\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfec59f4",
      "metadata": {
        "id": "dfec59f4"
      },
      "source": [
        "Nice! After three epochs we have a model accuracy of ~94%. Note that we didn't do a lot of work to filter the training data or tune hyperparameters for this experiment, and also that we used one of the smallest ESM-2 models. With a larger starting model and more effort to ensure that the training data categories were cleanly separable, accuracy could almost certainly go a lot higher!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc2ef458",
      "metadata": {
        "id": "bc2ef458"
      },
      "source": [
        "***\n",
        "# Token classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "78d701ed",
      "metadata": {
        "id": "78d701ed"
      },
      "source": [
        "Another common language model task is **token classification**. In this task, instead of classifying the whole sequence into a single category, we categorize each token (amino acid, in this case!) into one or more categories. This kind of model could be useful for:\n",
        "\n",
        "- Predicting secondary structure\n",
        "- Predicting buried vs. exposed residues\n",
        "- Predicting residues that will receive post-translational modifications\n",
        "- Predicting residues involved in binding pockets or active sites\n",
        "- Probably several other things, it's been a while since I was a postdoc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20e00afe",
      "metadata": {
        "id": "20e00afe"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1b9e75c",
      "metadata": {
        "id": "f1b9e75c"
      },
      "source": [
        "In this section, we're going to gather some training data from UniProt. As in the sequence classification example, we aim to create two lists: `sequences` and `labels`. Unlike in that example, however, the `labels` are more than just single integers. Instead, the label for each sample will be **one integer per token in the input**. This should make sense - when we do token classification, different tokens in the input may have different categories!\n",
        "\n",
        "To demonstrate token classification, we're going to go back to UniProt and get some data on protein secondary structures. As above, this will probably the main section you want to change when adapting this code to your own problems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "bf52cfb8",
      "metadata": {
        "id": "bf52cfb8"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "query_url =\"https://rest.uniprot.org/uniprotkb/stream?compressed=true&fields=accession%2Csequence%2Cft_strand%2Cft_helix&format=tsv&query=%28%28organism_id%3A9606%29%20AND%20%28reviewed%3Atrue%29%20AND%20%28length%3A%5B80%20TO%20500%5D%29%29\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73c902be",
      "metadata": {
        "id": "73c902be"
      },
      "source": [
        "This time, our UniProt search was `(organism_id:9606) AND (reviewed:true) AND (length:[100 TO 1000])` as it was in the first example, but instead of `Subcellular location [CC]` we take the `Helix` and `Beta strand` columns, as they contain the secondary structure information we want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "be65f529",
      "metadata": {
        "id": "be65f529"
      },
      "outputs": [],
      "source": [
        "uniprot_request = requests.get(query_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f683dd7",
      "metadata": {
        "id": "3f683dd7"
      },
      "source": [
        "To get this data into Pandas, we use a `BytesIO` object, which Pandas will treat like a file. If you downloaded the data as a file you can skip this bit and just pass the filepath directly to `read_csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "f49439ab",
      "metadata": {
        "id": "f49439ab",
        "outputId": "f90c824e-3206-467f-9927-2c1c92c3b1a5",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Entry</th>\n",
              "      <th>Sequence</th>\n",
              "      <th>Beta strand</th>\n",
              "      <th>Helix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A0A0K2S4Q6</td>\n",
              "      <td>MTQRAGAAMLPSALLLLCVPGCLTVSGPSTVMGAVGESLSVQCRYE...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A0AVI4</td>\n",
              "      <td>MDSPEVTFTLAYLVFAVCFVFTPNEFHAAGLTVQNLLSGWLGSEDA...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A0JLT2</td>\n",
              "      <td>MENFTALFGAQADPPPPPTALGFGPGKPPPPPPPPAGGGPGTAPPP...</td>\n",
              "      <td>STRAND 79..81; /evidence=\"ECO:0007829|PDB:7EMF\"</td>\n",
              "      <td>HELIX 83..86; /evidence=\"ECO:0007829|PDB:7EMF\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A0M8Q6</td>\n",
              "      <td>GQPKAAPSVTLFPPSSEELQANKATLVCLVSDFNPGAVTVAWKADG...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A0PJY2</td>\n",
              "      <td>MDSSCHNATTKMLATAPARGNMMSTSKPLAFSIERIMARTPEPKAL...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11985</th>\n",
              "      <td>Q9HBI5</td>\n",
              "      <td>MTSLFAQEIRLSKRHEEIVSQRLMLLQQMENKLGDQHTEKASQLQT...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11986</th>\n",
              "      <td>Q9NZ38</td>\n",
              "      <td>MAFPGQSDTKMQWPEVPALPLLSSLCMAMVRKSSALGKEVGRRSEG...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11987</th>\n",
              "      <td>Q9UFV3</td>\n",
              "      <td>MAETYRRSRQHEQLPGQRHMDLLTGYSKLIQSRLKLLLHLGSQPPV...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11988</th>\n",
              "      <td>Q9Y6C7</td>\n",
              "      <td>MAHHSLNTFYIWHNNVLHTHLVFFLPHLLNQPFSRGSFLIWLLLCW...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11989</th>\n",
              "      <td>X6R8R1</td>\n",
              "      <td>MGVVLSPHPAPSRREPLAPLAPGTRPGWSPAVSGSSRSALRPSTAG...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11990 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Entry                                           Sequence  \\\n",
              "0      A0A0K2S4Q6  MTQRAGAAMLPSALLLLCVPGCLTVSGPSTVMGAVGESLSVQCRYE...   \n",
              "1          A0AVI4  MDSPEVTFTLAYLVFAVCFVFTPNEFHAAGLTVQNLLSGWLGSEDA...   \n",
              "2          A0JLT2  MENFTALFGAQADPPPPPTALGFGPGKPPPPPPPPAGGGPGTAPPP...   \n",
              "3          A0M8Q6  GQPKAAPSVTLFPPSSEELQANKATLVCLVSDFNPGAVTVAWKADG...   \n",
              "4          A0PJY2  MDSSCHNATTKMLATAPARGNMMSTSKPLAFSIERIMARTPEPKAL...   \n",
              "...           ...                                                ...   \n",
              "11985      Q9HBI5  MTSLFAQEIRLSKRHEEIVSQRLMLLQQMENKLGDQHTEKASQLQT...   \n",
              "11986      Q9NZ38  MAFPGQSDTKMQWPEVPALPLLSSLCMAMVRKSSALGKEVGRRSEG...   \n",
              "11987      Q9UFV3  MAETYRRSRQHEQLPGQRHMDLLTGYSKLIQSRLKLLLHLGSQPPV...   \n",
              "11988      Q9Y6C7  MAHHSLNTFYIWHNNVLHTHLVFFLPHLLNQPFSRGSFLIWLLLCW...   \n",
              "11989      X6R8R1  MGVVLSPHPAPSRREPLAPLAPGTRPGWSPAVSGSSRSALRPSTAG...   \n",
              "\n",
              "                                           Beta strand  \\\n",
              "0                                                  NaN   \n",
              "1                                                  NaN   \n",
              "2      STRAND 79..81; /evidence=\"ECO:0007829|PDB:7EMF\"   \n",
              "3                                                  NaN   \n",
              "4                                                  NaN   \n",
              "...                                                ...   \n",
              "11985                                              NaN   \n",
              "11986                                              NaN   \n",
              "11987                                              NaN   \n",
              "11988                                              NaN   \n",
              "11989                                              NaN   \n",
              "\n",
              "                                                   Helix  \n",
              "0                                                    NaN  \n",
              "1                                                    NaN  \n",
              "2      HELIX 83..86; /evidence=\"ECO:0007829|PDB:7EMF\"...  \n",
              "3                                                    NaN  \n",
              "4                                                    NaN  \n",
              "...                                                  ...  \n",
              "11985                                                NaN  \n",
              "11986                                                NaN  \n",
              "11987                                                NaN  \n",
              "11988                                                NaN  \n",
              "11989                                                NaN  \n",
              "\n",
              "[11990 rows x 4 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from io import BytesIO\n",
        "import pandas\n",
        "\n",
        "bio = BytesIO(uniprot_request.content)\n",
        "\n",
        "df = pandas.read_csv(bio, compression='gzip', sep='\\t')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "736010f0",
      "metadata": {
        "id": "736010f0"
      },
      "source": [
        "Since not all proteins have this structural information, we discard proteins that have no annotated beta strands or alpha helices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "39ce9a5c",
      "metadata": {
        "id": "39ce9a5c",
        "outputId": "6152fe13-745c-467a-f024-199fde7945d3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Entry</th>\n",
              "      <th>Sequence</th>\n",
              "      <th>Beta strand</th>\n",
              "      <th>Helix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A0JLT2</td>\n",
              "      <td>MENFTALFGAQADPPPPPTALGFGPGKPPPPPPPPAGGGPGTAPPP...</td>\n",
              "      <td>STRAND 79..81; /evidence=\"ECO:0007829|PDB:7EMF\"</td>\n",
              "      <td>HELIX 83..86; /evidence=\"ECO:0007829|PDB:7EMF\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>A1L3X0</td>\n",
              "      <td>MAFSDLTSRTVHLYDNWIKDADPRVEDWLLMSSPLPQTILLGFYVY...</td>\n",
              "      <td>STRAND 97..99; /evidence=\"ECO:0007829|PDB:6Y7F\"</td>\n",
              "      <td>HELIX 17..20; /evidence=\"ECO:0007829|PDB:6Y7F\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>A1Z1Q3</td>\n",
              "      <td>MYPSNKKKKVWREEKERLLKMTLEERRKEYLRDYIPLNSILSWKEE...</td>\n",
              "      <td>STRAND 71..77; /evidence=\"ECO:0007829|PDB:4IQY...</td>\n",
              "      <td>HELIX 11..19; /evidence=\"ECO:0007829|PDB:4IQY\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>A2RUC4</td>\n",
              "      <td>MAGQHLPVPRLEGVSREQFMQHLYPQRKPLVLEGIDLGPCTSKWTV...</td>\n",
              "      <td>STRAND 10..13; /evidence=\"ECO:0007829|PDB:3AL5...</td>\n",
              "      <td>HELIX 16..22; /evidence=\"ECO:0007829|PDB:3AL5\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>A4D126</td>\n",
              "      <td>MEAGPPGSARPAEPGPCLSGQRGADHTASASLQSVAGTEPGRHPQA...</td>\n",
              "      <td>STRAND 45..52; /evidence=\"ECO:0007829|PDB:4CVH...</td>\n",
              "      <td>HELIX 76..85; /evidence=\"ECO:0007829|PDB:4CVH\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11624</th>\n",
              "      <td>Q9H0W7</td>\n",
              "      <td>MPTNCAAAGCATTYNKHINISFHRFPLDPKRRKEWVRLVRRKNFVP...</td>\n",
              "      <td>STRAND 7..9; /evidence=\"ECO:0007829|PDB:2D8R\";...</td>\n",
              "      <td>HELIX 29..38; /evidence=\"ECO:0007829|PDB:2D8R\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11661</th>\n",
              "      <td>Q9NVM6</td>\n",
              "      <td>MAVTKELLQMDLYALLGIEEKAADKEVKKAYRQKALSCHPDKNPDN...</td>\n",
              "      <td>STRAND 172..176; /evidence=\"ECO:0007829|PDB:2D...</td>\n",
              "      <td>HELIX 191..199; /evidence=\"ECO:0007829|PDB:2D9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11668</th>\n",
              "      <td>Q9P1F3</td>\n",
              "      <td>MNVDHEVNLLVEEIHRLGSKNADGKLSVKFGVLFRDDKCANLFEAL...</td>\n",
              "      <td>STRAND 24..29; /evidence=\"ECO:0007829|PDB:2L2O...</td>\n",
              "      <td>HELIX 3..17; /evidence=\"ECO:0007829|PDB:2L2O\";...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11670</th>\n",
              "      <td>Q9P298</td>\n",
              "      <td>MSANRRWWVPPDDEDCVSEKLLRKTRESPLVPIGLGGCLVVAAYRI...</td>\n",
              "      <td>STRAND 11..14; /evidence=\"ECO:0007829|PDB:2LON...</td>\n",
              "      <td>HELIX 18..24; /evidence=\"ECO:0007829|PDB:2LON\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11677</th>\n",
              "      <td>Q9UIY3</td>\n",
              "      <td>MSASVKESLQLQLLEMEMLFSMFPNQGEVKLEDVNALTNIKRYLEG...</td>\n",
              "      <td>STRAND 28..32; /evidence=\"ECO:0007829|PDB:2DAW...</td>\n",
              "      <td>HELIX 5..22; /evidence=\"ECO:0007829|PDB:2DAW\";...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4093 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Entry                                           Sequence  \\\n",
              "2      A0JLT2  MENFTALFGAQADPPPPPTALGFGPGKPPPPPPPPAGGGPGTAPPP...   \n",
              "13     A1L3X0  MAFSDLTSRTVHLYDNWIKDADPRVEDWLLMSSPLPQTILLGFYVY...   \n",
              "15     A1Z1Q3  MYPSNKKKKVWREEKERLLKMTLEERRKEYLRDYIPLNSILSWKEE...   \n",
              "19     A2RUC4  MAGQHLPVPRLEGVSREQFMQHLYPQRKPLVLEGIDLGPCTSKWTV...   \n",
              "21     A4D126  MEAGPPGSARPAEPGPCLSGQRGADHTASASLQSVAGTEPGRHPQA...   \n",
              "...       ...                                                ...   \n",
              "11624  Q9H0W7  MPTNCAAAGCATTYNKHINISFHRFPLDPKRRKEWVRLVRRKNFVP...   \n",
              "11661  Q9NVM6  MAVTKELLQMDLYALLGIEEKAADKEVKKAYRQKALSCHPDKNPDN...   \n",
              "11668  Q9P1F3  MNVDHEVNLLVEEIHRLGSKNADGKLSVKFGVLFRDDKCANLFEAL...   \n",
              "11670  Q9P298  MSANRRWWVPPDDEDCVSEKLLRKTRESPLVPIGLGGCLVVAAYRI...   \n",
              "11677  Q9UIY3  MSASVKESLQLQLLEMEMLFSMFPNQGEVKLEDVNALTNIKRYLEG...   \n",
              "\n",
              "                                             Beta strand  \\\n",
              "2        STRAND 79..81; /evidence=\"ECO:0007829|PDB:7EMF\"   \n",
              "13       STRAND 97..99; /evidence=\"ECO:0007829|PDB:6Y7F\"   \n",
              "15     STRAND 71..77; /evidence=\"ECO:0007829|PDB:4IQY...   \n",
              "19     STRAND 10..13; /evidence=\"ECO:0007829|PDB:3AL5...   \n",
              "21     STRAND 45..52; /evidence=\"ECO:0007829|PDB:4CVH...   \n",
              "...                                                  ...   \n",
              "11624  STRAND 7..9; /evidence=\"ECO:0007829|PDB:2D8R\";...   \n",
              "11661  STRAND 172..176; /evidence=\"ECO:0007829|PDB:2D...   \n",
              "11668  STRAND 24..29; /evidence=\"ECO:0007829|PDB:2L2O...   \n",
              "11670  STRAND 11..14; /evidence=\"ECO:0007829|PDB:2LON...   \n",
              "11677  STRAND 28..32; /evidence=\"ECO:0007829|PDB:2DAW...   \n",
              "\n",
              "                                                   Helix  \n",
              "2      HELIX 83..86; /evidence=\"ECO:0007829|PDB:7EMF\"...  \n",
              "13     HELIX 17..20; /evidence=\"ECO:0007829|PDB:6Y7F\"...  \n",
              "15     HELIX 11..19; /evidence=\"ECO:0007829|PDB:4IQY\"...  \n",
              "19     HELIX 16..22; /evidence=\"ECO:0007829|PDB:3AL5\"...  \n",
              "21     HELIX 76..85; /evidence=\"ECO:0007829|PDB:4CVH\"...  \n",
              "...                                                  ...  \n",
              "11624     HELIX 29..38; /evidence=\"ECO:0007829|PDB:2D8R\"  \n",
              "11661  HELIX 191..199; /evidence=\"ECO:0007829|PDB:2D9...  \n",
              "11668  HELIX 3..17; /evidence=\"ECO:0007829|PDB:2L2O\";...  \n",
              "11670  HELIX 18..24; /evidence=\"ECO:0007829|PDB:2LON\"...  \n",
              "11677  HELIX 5..22; /evidence=\"ECO:0007829|PDB:2DAW\";...  \n",
              "\n",
              "[4093 rows x 4 columns]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "no_structure_rows = df[\"Beta strand\"].isna() & df[\"Helix\"].isna()\n",
        "df = df[~no_structure_rows]\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f43e372c",
      "metadata": {
        "id": "f43e372c"
      },
      "source": [
        "Well, this works, but that data still isn't in a clean format that we can use to build our labels. Let's take a look at one sample to see what exactly we're dealing with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "73e99d1b",
      "metadata": {
        "id": "73e99d1b",
        "outputId": "7b4f4f4a-d073-4786-cfa4-9b0fe72d3244"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'HELIX 83..86; /evidence=\"ECO:0007829|PDB:7EMF\"; HELIX 90..96; /evidence=\"ECO:0007829|PDB:7EMF\"; HELIX 112..116; /evidence=\"ECO:0007829|PDB:7EMF\"; HELIX 128..138; /evidence=\"ECO:0007829|PDB:7EMF\"; HELIX 147..152; /evidence=\"ECO:0007829|PDB:7EMF\"'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.iloc[0][\"Helix\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cd5160a",
      "metadata": {
        "id": "6cd5160a"
      },
      "source": [
        "We'll need to use a [regex](https://docs.python.org/3/howto/regex.html) to pull out each segment that's marked as being a STRAND or HELIX. What we're asking for is a list of everywhere we see the word STRAND or HELIX followed by two numbers separated by two dots. In each case where this pattern is found, we tell the regex to extract the two numbers as a tuple for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "7540949e",
      "metadata": {
        "id": "7540949e",
        "outputId": "a777d71c-6431-4b9b-cf9f-9e7afaaeeb12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('83', '86'), ('90', '96'), ('112', '116'), ('128', '138'), ('147', '152')]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "strand_re = r\"STRAND\\s(\\d+)\\.\\.(\\d+)\\;\"\n",
        "helix_re = r\"HELIX\\s(\\d+)\\.\\.(\\d+)\\;\"\n",
        "\n",
        "re.findall(helix_re, df.iloc[0][\"Helix\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4457b1a0",
      "metadata": {
        "id": "4457b1a0"
      },
      "source": [
        "Looks good! We can use this to build our training data. Recall that the **labels** need to be a list or array of integers that's the same length as the input sequence. We're going to use 0 to indicate residues without any annotated structure, 1 for residues in an alpha helix, and 2 for residues in a beta strand. To build that, we'll start with an array of all 0s, and then fill in values based on the positions that our regex pulls out of the UniProt results.\n",
        "\n",
        "We'll use NumPy arrays rather than lists here, since these allow [slice assignment](https://numpy.org/doc/stable/user/basics.indexing.html#assigning-values-to-indexed-arrays), which will be a lot simpler than editing a list of integers. Note also that UniProt annotates residues starting from 1 (unlike Python, which starts from 0), and region annotations are inclusive (so 1..3 means residues 1, 2 and 3). To turn these into Python slices, we subtract 1 from the start of each annotation, but not the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "a4c97179",
      "metadata": {
        "id": "a4c97179"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def build_labels(sequence, strands, helices):\n",
        "    # Start with all 0s\n",
        "    labels = np.zeros(len(sequence), dtype=np.int64)\n",
        "\n",
        "    if isinstance(helices, float): # Indicates missing (NaN)\n",
        "        found_helices = []\n",
        "    else:\n",
        "        found_helices = re.findall(helix_re, helices)\n",
        "    for helix_start, helix_end in found_helices:\n",
        "        helix_start = int(helix_start) - 1\n",
        "        helix_end = int(helix_end)\n",
        "        assert helix_end <= len(sequence)\n",
        "        labels[helix_start: helix_end] = 1  # Helix category\n",
        "\n",
        "    if isinstance(strands, float): # Indicates missing (NaN)\n",
        "        found_strands = []\n",
        "    else:\n",
        "        found_strands = re.findall(strand_re, strands)\n",
        "    for strand_start, strand_end in found_strands:\n",
        "        strand_start = int(strand_start) - 1\n",
        "        strand_end = int(strand_end)\n",
        "        assert strand_end <= len(sequence)\n",
        "        labels[strand_start: strand_end] = 2  # Strand category\n",
        "    return labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ad7e7fd",
      "metadata": {
        "id": "5ad7e7fd"
      },
      "source": [
        "Now we've defined a helper function, let's build our lists of sequences and labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "313811fe",
      "metadata": {
        "id": "313811fe"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "labels = []\n",
        "\n",
        "for row_idx, row in df.iterrows():\n",
        "    row_labels = build_labels(row[\"Sequence\"], row[\"Beta strand\"], row[\"Helix\"])\n",
        "    sequences.append(row[\"Sequence\"])\n",
        "    labels.append(row_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e8b3ba8",
      "metadata": {
        "id": "8e8b3ba8"
      },
      "source": [
        "## Creating our dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e619d9ae",
      "metadata": {
        "id": "e619d9ae"
      },
      "source": [
        "Nice! Now we'll split and tokenize the data, and then create datasets - I'll go through this quite quickly here, since it's identical to how we did it in the sequence classification example above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "3c208c30",
      "metadata": {
        "id": "3c208c30"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sequences, test_sequences, train_labels, test_labels = train_test_split(sequences, labels, test_size=0.25, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "2182fae2",
      "metadata": {
        "id": "2182fae2",
        "outputId": "277ddb32-6030-45e5-cd47-3a8a5e05e6a6"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "train_tokenized = tokenizer(train_sequences)\n",
        "test_tokenized = tokenizer(test_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "3939f13a",
      "metadata": {
        "id": "3939f13a"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "train_dataset = Dataset.from_dict(train_tokenized)\n",
        "test_dataset = Dataset.from_dict(test_tokenized)\n",
        "\n",
        "train_dataset = train_dataset.add_column(\"labels\", train_labels)\n",
        "test_dataset = test_dataset.add_column(\"labels\", test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4766fe4b",
      "metadata": {
        "id": "4766fe4b"
      },
      "source": [
        "## Model loading"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de8419b5",
      "metadata": {
        "id": "de8419b5"
      },
      "source": [
        "The key difference here with the above example is that we use `AutoModelForTokenClassification` instead of `AutoModelForSequenceClassification`. We will also need a `data_collator` this time, as we're in the slightly more complex case where both inputs and labels must be padded in each batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "4b26b828",
      "metadata": {
        "id": "4b26b828",
        "outputId": "cca58257-84a4-4dd4-c669-b0d963ee2cbd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of EsmForTokenClassification were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "\n",
        "num_labels = 3\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "eec0005a",
      "metadata": {
        "id": "eec0005a"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd3c7305",
      "metadata": {
        "id": "bd3c7305"
      },
      "source": [
        "Now we set up our `TrainingArguments` as before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "e7724323",
      "metadata": {
        "id": "e7724323",
        "outputId": "38145342-79b7-412b-d88e-0e0b6c3ae8a0"
      },
      "outputs": [],
      "source": [
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "batch_size = 8\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"{model_name}-finetuned-secondary-structure\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=1e-4,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.001,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    push_to_hub=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb5fba9a",
      "metadata": {
        "id": "fb5fba9a"
      },
      "source": [
        "Our `compute_metrics` function is a bit more complex than in the sequence classification task, as we need to ignore padding tokens (those where the label is `-100`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "736886a0",
      "metadata": {
        "id": "736886a0"
      },
      "outputs": [],
      "source": [
        "from evaluate import load\n",
        "import numpy as np\n",
        "\n",
        "metric = load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    labels = labels.reshape((-1,))\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "    predictions = predictions.reshape((-1,))\n",
        "    predictions = predictions[labels!=-100]\n",
        "    labels = labels[labels!=-100]\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37491af5",
      "metadata": {
        "id": "37491af5"
      },
      "source": [
        "And now we're ready to train our model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "4c97836c",
      "metadata": {
        "id": "4c97836c",
        "outputId": "ac7d2c37-82b0-4dc0-9ec2-92a106ecff82"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3835af4a3314134a35435e0abca09c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1152 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/amalicema24/Downloads/esm2_pytorch/protein_language_modeling.ipynb Cell 97\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amalicema24/Downloads/esm2_pytorch/protein_language_modeling.ipynb#Y163sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amalicema24/Downloads/esm2_pytorch/protein_language_modeling.ipynb#Y163sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amalicema24/Downloads/esm2_pytorch/protein_language_modeling.ipynb#Y163sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amalicema24/Downloads/esm2_pytorch/protein_language_modeling.ipynb#Y163sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     data_collator\u001b[39m=\u001b[39mdata_collator,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amalicema24/Downloads/esm2_pytorch/protein_language_modeling.ipynb#Y163sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/amalicema24/Downloads/esm2_pytorch/protein_language_modeling.ipynb#Y163sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/transformers/trainer.py:1546\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     \u001b[39m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   1545\u001b[0m     hf_hub_utils\u001b[39m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 1546\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1547\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1548\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1549\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1550\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1551\u001b[0m     )\n\u001b[1;32m   1552\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1553\u001b[0m     hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/transformers/trainer.py:1837\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1834\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   1836\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1837\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1839\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1840\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1841\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1842\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1843\u001b[0m ):\n\u001b[1;32m   1844\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1845\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/transformers/trainer.py:2682\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2679\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   2681\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2682\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   2684\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2685\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/transformers/trainer.py:2707\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2705\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2706\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2707\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   2708\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2709\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2710\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py:1212\u001b[0m, in \u001b[0;36mEsmForTokenClassification.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1207\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1208\u001b[0m \u001b[39m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001b[39;00m\n\u001b[1;32m   1209\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1212\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mesm(\n\u001b[1;32m   1213\u001b[0m     input_ids,\n\u001b[1;32m   1214\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1215\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1216\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1217\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1218\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1219\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1220\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1221\u001b[0m )\n\u001b[1;32m   1223\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1225\u001b[0m sequence_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(sequence_output)\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py:924\u001b[0m, in \u001b[0;36mEsmModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    915\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    917\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    918\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    919\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    922\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    923\u001b[0m )\n\u001b[0;32m--> 924\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    925\u001b[0m     embedding_output,\n\u001b[1;32m    926\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    927\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    928\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    929\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m    930\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    931\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    932\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    933\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    934\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    935\u001b[0m )\n\u001b[1;32m    936\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    937\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py:624\u001b[0m, in \u001b[0;36mEsmEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    615\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    616\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    617\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    621\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    622\u001b[0m     )\n\u001b[1;32m    623\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 624\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    625\u001b[0m         hidden_states,\n\u001b[1;32m    626\u001b[0m         attention_mask,\n\u001b[1;32m    627\u001b[0m         layer_head_mask,\n\u001b[1;32m    628\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    629\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    630\u001b[0m         past_key_value,\n\u001b[1;32m    631\u001b[0m         output_attentions,\n\u001b[1;32m    632\u001b[0m     )\n\u001b[1;32m    634\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py:509\u001b[0m, in \u001b[0;36mEsmLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    498\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    499\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    506\u001b[0m ):\n\u001b[1;32m    507\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    508\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    510\u001b[0m         hidden_states,\n\u001b[1;32m    511\u001b[0m         attention_mask,\n\u001b[1;32m    512\u001b[0m         head_mask,\n\u001b[1;32m    513\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    514\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    515\u001b[0m     )\n\u001b[1;32m    516\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    518\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py:443\u001b[0m, in \u001b[0;36mEsmAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    433\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    434\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    441\u001b[0m ):\n\u001b[1;32m    442\u001b[0m     hidden_states_ln \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states)\n\u001b[0;32m--> 443\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    444\u001b[0m         hidden_states_ln,\n\u001b[1;32m    445\u001b[0m         attention_mask,\n\u001b[1;32m    446\u001b[0m         head_mask,\n\u001b[1;32m    447\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    448\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    449\u001b[0m         past_key_value,\n\u001b[1;32m    450\u001b[0m         output_attentions,\n\u001b[1;32m    451\u001b[0m     )\n\u001b[1;32m    452\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[1;32m    453\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/envo/lib/python3.11/site-packages/transformers/models/esm/modeling_esm.py:380\u001b[0m, in \u001b[0;36mEsmSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39mif\u001b[39;00m head_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     attention_probs \u001b[39m=\u001b[39m attention_probs \u001b[39m*\u001b[39m head_mask\n\u001b[0;32m--> 380\u001b[0m context_layer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(attention_probs, value_layer)\n\u001b[1;32m    382\u001b[0m context_layer \u001b[39m=\u001b[39m context_layer\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\n\u001b[1;32m    383\u001b[0m new_context_layer_shape \u001b[39m=\u001b[39m context_layer\u001b[39m.\u001b[39msize()[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_head_size,)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f503fc00",
      "metadata": {
        "id": "f503fc00"
      },
      "source": [
        "This definitely seems harder than the first task, but we still attain a very respectable accuracy. Remember that to keep this demo lightweight, we used one of the smallest ESM models, focused on human proteins only and didn't put a lot of work into making sure we only included completely-annotated proteins in our training set. With a bigger model and a cleaner, broader training set, accuracy on this task could definitely go a lot higher!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
